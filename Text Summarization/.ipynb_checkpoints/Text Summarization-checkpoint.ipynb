{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was published at https://github.com/duyvuleo/VNTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will implement some algorithms to apply in text summarization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Text Summarization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text summarization is the problem of creating a short, accurate, and fluent summary of a longer text document.\n",
    "\n",
    "Automatic text summarization methods are greatly needed to address the ever-growing amount of text data available online to both better help discover relevant information and to consume relevant information faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What will we do in this tutorial?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will solve Text Summarization for Vietnamese newspapers, using some algorithms belows:\n",
    "1. Extractive Text Summarization\n",
    "    - Doc2Vec\n",
    "    - Text Rank\n",
    "2. Abstractive Text Summarization\n",
    "    - Google textsum\n",
    "\n",
    "\n",
    "We just implement \"**Single document summarization**\" problem in this tutorial, another problem called \"**Multi-document summarization**\" will be dicussed in another time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractive Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example: https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic idea\n",
    "The idea of using Doc2Vec algorithm for text summarization problem is described as follows:\n",
    "1. In all documents, we will extract sentences separately.\n",
    "2. Each sentence will be represented by a vector, via doc2vec model\n",
    "3. Use KMean algorithm to find out most featured sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "dir_path = os.path.join(dir_path, 'Data')\n",
    "\n",
    "sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_data(folder):\n",
    "    sentences = []\n",
    "    for path in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, path)\n",
    "        with open(file_path, 'r', encoding=\"utf-16\") as f:\n",
    "\n",
    "            lines = f.readlines()\n",
    "\n",
    "            for line in lines:\n",
    "                sens = line.split('.')\n",
    "                for sen in sens:\n",
    "                    if len(sen) > 10:\n",
    "                        sen = gensim.utils.simple_preprocess(sen)\n",
    "                        sen = ' '.join(sen)\n",
    "                        sen = ViTokenizer.tokenize(sen)\n",
    "                        sentences.append(sen)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use multiprocessing here, but we will not use it for easy in understanding code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "# sentences = []\n",
    "# train_paths = [os.path.join(dir_path, 'VNTC-master/Data/10Topics/Ver1.1/Train_Full'), \n",
    "#                os.path.join(dir_path, 'VNTC-master/Data/10Topics/Ver1.1/Test_Full'),\n",
    "#                os.path.join(dir_path, 'VNTC-master/Data/27Topics/Ver1.1/new train'),\n",
    "#                os.path.join(dir_path, 'VNTC-master/Data/27Topics/Ver1.1/new test')]\n",
    "\n",
    "# dirs = []\n",
    "# for path in train_paths:\n",
    "#     for p in os.listdir(path):\n",
    "#         dirs.append(os.path.join(path, p))\n",
    "\n",
    "# for d in tqdm(dirs):\n",
    "#     sens = get_data(d)\n",
    "#     sentences = sentences + sens\n",
    "\n",
    "# # with Pool(8) as pool:\n",
    "# #     pool.map(get_data, tqdm(dirs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(sentences, open('./sentences.pkl', 'wb'))\n",
    "sentences = pickle.load(open('./sentences.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(sentences):\n",
    "    corpus = []\n",
    "    \n",
    "    for i in tqdm(range(len(sentences))):\n",
    "        sen = sentences[i]\n",
    "        \n",
    "        words = sen.split(' ')\n",
    "        tagged_document = gensim.models.doc2vec.TaggedDocument(words, [i])\n",
    "        \n",
    "        corpus.append(tagged_document)\n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2385532/2385532 [00:46<00:00, 50865.69it/s]\n"
     ]
    }
   ],
   "source": [
    "train_corpus = get_corpus(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_corpus = shuffle(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=300, min_count=2, epochs=40)\n",
    "model.build_vocab(train_corpus[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.9 s, sys: 8.34 s, total: 51.2 s\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%time model.train(train_corpus[:10000], total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04341994,  0.15068059, -0.17990573,  0.13434036,  0.15063864,\n",
       "       -0.28319448,  0.01176064,  0.13072975, -0.16741212,  0.05707793,\n",
       "        0.17512715,  0.11362587, -0.14895017,  0.12809876,  0.2387469 ,\n",
       "        0.17342958, -0.0634373 ,  0.02054051,  0.19843611,  0.00898704,\n",
       "        0.22812013, -0.03727509,  0.23731954,  0.16173142, -0.16983813,\n",
       "       -0.00564219,  0.12142332, -0.20086913, -0.20483473,  0.09911519,\n",
       "       -0.27930656,  0.00869519,  0.13946147, -0.1438239 , -0.18420076,\n",
       "        0.3448807 ,  0.02739131, -0.12618671,  0.39163232,  0.3807378 ,\n",
       "        0.05839496,  0.13358061,  0.01925733, -0.0135405 , -0.16153328,\n",
       "        0.02138443,  0.01873437, -0.20007984, -0.11788367, -0.05585638,\n",
       "       -0.25569782, -0.20820048, -0.00627773,  0.21006308,  0.18283018,\n",
       "        0.09105326, -0.06296346,  0.0032261 , -0.22849984,  0.13495123,\n",
       "        0.1795704 , -0.14362498, -0.06998537,  0.16478956, -0.06558435,\n",
       "       -0.09611794,  0.03294007, -0.10089063,  0.09843311, -0.13907026,\n",
       "       -0.27365705,  0.30230847,  0.40530467,  0.09563513, -0.02210305,\n",
       "       -0.06091335,  0.1563382 ,  0.00895904,  0.18720831, -0.14001934,\n",
       "        0.01387348, -0.32348102,  0.09674963,  0.15495019,  0.2114251 ,\n",
       "       -0.17900814,  0.10442318, -0.04665227,  0.02126863, -0.49398616,\n",
       "        0.05436768,  0.2409514 , -0.26541945,  0.22139902,  0.23056166,\n",
       "       -0.13290638, -0.15834005, -0.05093888, -0.2010437 , -0.00872721,\n",
       "       -0.2170396 , -0.12871493, -0.35905242,  0.08654048,  0.16774806,\n",
       "       -0.3187868 ,  0.05390566,  0.0159378 , -0.20821764,  0.00432084,\n",
       "       -0.02714869, -0.1688966 ,  0.07739182,  0.03632382,  0.06650626,\n",
       "        0.04891365, -0.25082728,  0.12104706,  0.01196582,  0.21224128,\n",
       "        0.04687948, -0.03495178,  0.3255804 ,  0.0175802 ,  0.03234688,\n",
       "        0.00244484, -0.09091838, -0.01832044, -0.00486469,  0.14132531,\n",
       "       -0.13066027, -0.133963  ,  0.08546828, -0.20010397,  0.13923682,\n",
       "       -0.1636201 , -0.11846109, -0.07207088,  0.01004884, -0.13079908,\n",
       "        0.04369699, -0.10263414,  0.2704738 , -0.02805597, -0.01418491,\n",
       "       -0.10934044, -0.05642736,  0.17936125,  0.04352818,  0.10867421,\n",
       "        0.32129163,  0.046547  ,  0.13372496,  0.27983844,  0.02909526,\n",
       "        0.1940122 ,  0.01545601, -0.30535015, -0.15497243, -0.16135946,\n",
       "       -0.17891252, -0.2534565 ,  0.3138783 ,  0.14041126, -0.37740913,\n",
       "        0.01908436,  0.05203399,  0.21451457,  0.00417452,  0.06932773,\n",
       "        0.19613068,  0.22338638,  0.08993655,  0.05162952, -0.1715082 ,\n",
       "       -0.04873776, -0.16500841,  0.06663296,  0.23246402, -0.08794285,\n",
       "       -0.23133302,  0.03798284, -0.28734875, -0.11884663, -0.3873993 ,\n",
       "        0.05391167,  0.17511298, -0.12214469, -0.15087114, -0.00648386,\n",
       "       -0.34489504, -0.00081781,  0.3112306 , -0.01988143,  0.09800355,\n",
       "       -0.01796208,  0.12675954,  0.07986449, -0.25173518, -0.05057919,\n",
       "       -0.02710901,  0.01427647,  0.21491455, -0.02798258,  0.20607495,\n",
       "       -0.00942707,  0.0222345 , -0.27584273,  0.21077009, -0.02589862,\n",
       "        0.06877273,  0.1596887 , -0.01745787, -0.23009653,  0.12250713,\n",
       "       -0.07652903,  0.19852011,  0.06020096,  0.14080118, -0.04491249,\n",
       "       -0.09397829, -0.07017988,  0.05635121, -0.16365536,  0.27378193,\n",
       "       -0.09063263, -0.17539304,  0.5473707 , -0.05879439,  0.31840223,\n",
       "       -0.14012551,  0.05181855,  0.23555908,  0.11351999, -0.07567175,\n",
       "       -0.03333608,  0.20951699, -0.01374531, -0.3616348 ,  0.31039193,\n",
       "       -0.17454425,  0.3302186 ,  0.07503787,  0.18425031, -0.03812596,\n",
       "       -0.16169602, -0.2283107 ,  0.06445627,  0.46395943,  0.18987691,\n",
       "        0.15003437, -0.03523616, -0.04401125,  0.23554291, -0.27746007,\n",
       "       -0.05590428, -0.00676751,  0.0676496 , -0.22452983, -0.16342208,\n",
       "        0.14932774, -0.28333095, -0.01125666,  0.10429596, -0.18696538,\n",
       "       -0.00179594,  0.04852985, -0.0064008 ,  0.42234132, -0.04479992,\n",
       "       -0.08885661, -0.04996622,  0.05248848,  0.05441889, -0.09043926,\n",
       "        0.2754019 , -0.09798148,  0.10865667,  0.06042345, -0.06642479,\n",
       "        0.33543497, -0.4296108 , -0.23069882, -0.15536407, -0.17023668,\n",
       "        0.04889965, -0.06179199, -0.06804086, -0.21708992, -0.02921593,\n",
       "       -0.15509202, -0.02368613,  0.19768919, -0.11546308, -0.14237164,\n",
       "       -0.06311936, -0.00546007, -0.07549815,  0.36970434, -0.2988238 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(train_corpus[100000].words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with new document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_sentence_vectors_from_document(doc, model):\n",
    "    vectors = []\n",
    "    sens = doc.split('.')\n",
    "    for sen in sens:\n",
    "        if len(sen) > 10:\n",
    "            sen = gensim.utils.simple_preprocess(sen)\n",
    "            sen = ' '.join(sen)\n",
    "            sen = ViTokenizer.tokenize(sen)\n",
    "            sen = sen.split(' ')\n",
    "            vec = model.infer_vector(sen)\n",
    "            \n",
    "            vectors.append(vec)\n",
    "    \n",
    "    return np.array(vectors), sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"Chiều 24/10, Công an quận 2, TP.HCM cho biết đã tìm thấy ô tô biển xanh 80B-3758 bật còi ưu tiên, chạy trên nhiều tuyến đường ở quận 2 sau đó đến trước một công ty bất động sản trên địa bàn. Theo công an, người điều khiển phương tiện là ông Đ.M.T. đang làm ở quận 2. “Chúng tôi đang tạm giữ phương tiện, lấy lời khai tài xế để làm rõ vụ việc”, Công an quận 2 thông tin. Theo công an, tại thời điểm bị tạm giữ, ông T không xuất trình được giấy tờ chứng minh nguồn gốc ô tô BKS: 80B - 3758. Ông T thừa nhận mượn xe này từ một người bạn rồi sang quận 2 đi chơi. Lộ diện tài xế lái ô tô biển xanh 80B giả bật còi ưu tiên, phóng trên đường. Ô tô biển xanh 80B giả liên tục bật còi ưu tiên phóng với tốc độ nhanh trên đường Trước đó, khoảng gần 19h ngày 20/10, chiếc ô tô mang biển số xanh 80B-3758 do người đàn ông điều khiển lưu thông từ giao lộ An Phú – đường cao tốc TPHCM – Long Thành – Dầu Giây về đường Nguyễn Thị Định rồi qua cầu Giồng Ông Tố 1 rẽ trái hướng về đường Nguyễn Duy Trinh, Lê Văn Thịnh… thuộc địa bàn quận 2. Lộ diện tài xế lái ô tô biển xanh 80B giả bật còi ưu tiên, phóng trên đường. Khi tới một công ty bất động sản, những người trên ô tô xuống xe đi vào bên trong khoảng 15 phút Trên đường đi, chiếc xe nói trên liên tục bật dàn đèn ưu tiên phía trước kính chắn gió, hú còi inh ỏi, lấn trái để chạy với tốc độ rất nhanh. Nhiều người vội vã nhường đường vì ai cũng cho rằng chiếc xe biển xanh đang sử dụng quyền ưu tiên để đi công vụ khẩn cấp. Thậm chí, khi nhìn thấy trên xe có 1 phụ nữ và 2 trẻ em ngồi trong xe, không ít người dù bất ngờ nhưng cũng bày tỏ sự thông cảm vì nghĩ rằng, có khả năng xe đang chở người đến bệnh viện quận 2 cấp cứu. Tuy nhiên, khi đến đường số 28 (phường Cát Lái, quận 2) ô tô dừng lại trước một công ty bất động sản, những người trên xe sau đó bấm chuông và đi vào bên trong căn nhà.\"\n",
    "\n",
    "sen_vectors = get_list_sentence_vectors_from_document(doc, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 300)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sen_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "kmeans = kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "avg = []\n",
    "for j in range(n_clusters):\n",
    "    idx = np.where(kmeans.labels_ == j)[0]\n",
    "    avg.append(np.mean(idx))\n",
    "closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, X)\n",
    "ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n",
    "summary = ' '.join([sentences[closest[idx]] for idx in ordering])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thất_thoát_tỷ đồng trong vụ tiêu_cực vietsovpetro tất_nhiên đây sẽ phải là đội_hình mạnh nhất bởi một kết_quả thua argentina cũng đồng_nghĩa với niềm kiêu_hãnh của xứ_sở sương_mù bị tổn_thương nghiêm_trọng sản_phẩm được trang_bị màn_hình qvga lcd inch hỗ_trợ cây hồi chữa bệnh gì cô có những phương_cách tiếp_cận phù_hợp với từng lứa tuổi và dễ_dàng vượt qua những rào_cản về khác_biệt văn_hóa_đây là nhận_xét của hiệp_hội những chuyên_gia kể chuyện châu'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
