{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was published at https://github.com/duyvuleo/VNTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will implement some algorithms to apply in text summarization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Text Summarization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text summarization is the problem of creating a short, accurate, and fluent summary of a longer text document.\n",
    "\n",
    "Automatic text summarization methods are greatly needed to address the ever-growing amount of text data available online to both better help discover relevant information and to consume relevant information faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What will we do in this tutorial?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will solve Text Summarization for Vietnamese newspapers, using some algorithms belows:\n",
    "1. Extractive Text Summarization\n",
    "    - Doc2Vec\n",
    "    - Text Rank\n",
    "2. Abstractive Text Summarization\n",
    "    - Google textsum\n",
    "\n",
    "\n",
    "We just implement \"**Single document summarization**\" problem in this tutorial, another problem called \"**Multi-document summarization**\" will be dicussed in another time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractive Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example: https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic idea\n",
    "The idea of using Doc2Vec algorithm for text summarization problem is described as follows:\n",
    "1. In all documents, we will extract sentences separately.\n",
    "2. Each sentence will be represented by a vector, via doc2vec model\n",
    "3. Use KMean algorithm to find out most featured sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "dir_path = os.path.join(dir_path, 'Data')\n",
    "\n",
    "sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_data(folder):\n",
    "    sentences = []\n",
    "    for path in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, path)\n",
    "        with open(file_path, 'r', encoding=\"utf-16\") as f:\n",
    "\n",
    "            lines = f.readlines()\n",
    "\n",
    "            for line in lines:\n",
    "                sens = line.split('.')\n",
    "                for sen in sens:\n",
    "                    if len(sen) > 10:\n",
    "                        sen = gensim.utils.simple_preprocess(sen)\n",
    "                        sen = ' '.join(sen)\n",
    "                        sen = ViTokenizer.tokenize(sen)\n",
    "                        sentences.append(sen)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use multiprocessing here, but we will not use it for easy in understanding code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "# sentences = []\n",
    "train_paths = [os.path.join(dir_path, 'VNTC-master/Data/10Topics/Ver1.1/Train_Full'), \n",
    "               os.path.join(dir_path, 'VNTC-master/Data/10Topics/Ver1.1/Test_Full'),\n",
    "               os.path.join(dir_path, 'VNTC-master/Data/27Topics/Ver1.1/new train'),\n",
    "               os.path.join(dir_path, 'VNTC-master/Data/27Topics/Ver1.1/new test')]\n",
    "\n",
    "# dirs = []\n",
    "# for path in train_paths:\n",
    "#     for p in os.listdir(path):\n",
    "#         dirs.append(os.path.join(path, p))\n",
    "\n",
    "# for d in tqdm(dirs):\n",
    "#     sens = get_data(d)\n",
    "#     sentences = sentences + sens\n",
    "\n",
    "# # with Pool(8) as pool:\n",
    "# #     pool.map(get_data, tqdm(dirs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(sentences, open('./sentences.pkl', 'wb'))\n",
    "sentences = pickle.load(open('./sentences.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(sentences):\n",
    "    corpus = []\n",
    "    \n",
    "    for i in tqdm(range(len(sentences))):\n",
    "        sen = sentences[i]\n",
    "        \n",
    "        words = sen.split(' ')\n",
    "        tagged_document = gensim.models.doc2vec.TaggedDocument(words, [i])\n",
    "        \n",
    "        corpus.append(tagged_document)\n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2385532/2385532 [00:46<00:00, 50865.69it/s]\n"
     ]
    }
   ],
   "source": [
    "train_corpus = get_corpus(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_corpus = shuffle(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=300, min_count=2, epochs=40)\n",
    "model.build_vocab(train_corpus[:50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 55s, sys: 46.1 s, total: 4min 41s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%time model.train(train_corpus[:50000], total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01640272,  0.30293402, -0.02834823,  0.13452004, -0.07659013,\n",
       "       -0.33132985, -0.00480685,  0.2618827 , -0.48799312, -0.21672371,\n",
       "        0.10400254, -0.13873473, -0.10735019, -0.10271706,  0.16801126,\n",
       "        0.33499536, -0.25886083,  0.07081345,  0.264569  ,  0.13980535,\n",
       "        0.26452696,  0.09870374, -0.5529773 ,  0.3120131 ,  0.0372953 ,\n",
       "        0.07732704, -0.03702435, -0.15923078,  0.01857543,  0.04388041,\n",
       "       -0.33324614,  0.3492984 ,  0.05055666,  0.01133657,  0.16621178,\n",
       "       -0.19090281,  0.00738728, -0.23280129,  0.28164917,  0.28299242,\n",
       "       -0.61318856,  0.30712935,  0.25316742,  0.00267887,  0.27907962,\n",
       "       -0.21710835, -0.13867892, -0.05219948,  0.29381886, -0.32117757,\n",
       "        0.29475835,  0.17440887, -0.14471418,  0.09133102,  0.11118025,\n",
       "       -0.09764334, -0.11072824,  0.00535384, -0.06201801,  0.73688567,\n",
       "        0.391858  , -0.2384683 ,  0.12680122, -0.30809587,  0.1182595 ,\n",
       "       -0.16347682,  0.03030134, -0.16919139, -0.15018974,  0.54758674,\n",
       "        0.04899409,  0.29510507, -0.25957635,  0.16718113, -0.23877673,\n",
       "       -0.30308366, -0.31280786, -0.23688154,  0.01306701, -0.25799462,\n",
       "        0.02433853, -0.10075156, -0.06774618, -0.52915716,  0.22499399,\n",
       "        0.05221445,  0.07804999,  0.11724031,  0.3253076 , -0.4135057 ,\n",
       "        0.10126988,  0.08063246, -0.14797762, -0.29653132, -0.2211966 ,\n",
       "       -0.21349575,  0.03118307,  0.5949105 , -0.03754237, -0.16347578,\n",
       "       -0.13092218,  0.46461207, -0.06964463,  0.06461693,  0.04568142,\n",
       "       -0.03058051, -0.10980988, -0.26234818,  0.01482217, -0.3633959 ,\n",
       "       -0.23585357, -0.01596291,  0.3303342 ,  0.1320441 , -0.2679122 ,\n",
       "        0.23723869, -0.08185412,  0.41218406,  0.3924499 ,  0.04274316,\n",
       "        0.07246857, -0.3245881 , -0.24946196,  0.00517888,  0.3236268 ,\n",
       "       -0.40705943, -0.0432242 , -0.01460427, -0.3996217 ,  0.45899194,\n",
       "        0.11351302,  0.05986802, -0.04692668, -0.11684551,  0.15355155,\n",
       "        0.00617072, -0.21483473,  0.36976346,  0.26950926, -0.23292106,\n",
       "        0.146911  , -0.36638775, -0.34492868, -0.3614157 ,  0.00798225,\n",
       "       -0.26599354, -0.50669605,  0.25100666,  0.28771356, -0.3610674 ,\n",
       "        0.19677573,  0.2934402 , -0.33580965,  0.06836133,  0.45954835,\n",
       "       -0.39486402, -0.12859869,  0.18963675,  0.42306954, -0.44573298,\n",
       "        0.09713407,  0.21913077,  0.396599  ,  0.34815228,  0.15605003,\n",
       "        0.14553367, -0.06294132,  0.14968082, -0.46609893,  0.1318323 ,\n",
       "        0.23163858, -0.10849379,  0.06413414,  0.32593647, -0.22598445,\n",
       "        0.18911627, -0.12938558, -0.01182354,  0.0247075 , -0.28241763,\n",
       "        0.00891759, -0.16429865, -0.3196875 , -0.13499986, -0.53718257,\n",
       "       -0.23789765, -0.01652647, -0.35017297,  0.07855523, -0.0474344 ,\n",
       "        0.47509703,  0.03010933, -0.01768847,  0.26980764, -0.12735188,\n",
       "        0.00354339,  0.00208599,  0.06627135,  0.07760119,  0.29552338,\n",
       "        0.0647604 ,  0.20856206, -0.155291  ,  0.01526389,  0.1700401 ,\n",
       "        0.10601519, -0.04171611, -0.21581836,  0.65862894, -0.21313886,\n",
       "        0.32469848, -0.32862264,  0.0103419 , -0.22988226, -0.0956108 ,\n",
       "       -0.33579087, -0.0436952 ,  0.23565263,  0.28841835, -0.05045816,\n",
       "        0.05429307,  0.2323167 , -0.23261197, -0.15813737,  0.15256454,\n",
       "        0.22201598, -0.3481181 ,  0.27363878, -0.14204304,  0.19368997,\n",
       "       -0.2231416 ,  0.2792028 ,  0.08873835,  0.18433726, -0.13744514,\n",
       "        0.16841927,  0.22275648, -0.27939078, -0.07116818, -0.12040913,\n",
       "       -0.07934032,  0.03137737, -0.03915448, -0.09669876, -0.34206423,\n",
       "       -0.145499  , -0.26018426, -0.04987361, -0.04705151,  0.3348471 ,\n",
       "        0.32905054,  0.36489293, -0.20489018,  0.51635146, -0.28033334,\n",
       "        0.22707969,  0.05233236,  0.26688358, -0.01997004, -0.7320433 ,\n",
       "       -0.21607201,  0.42162347, -0.15802984, -0.28555432,  0.3773995 ,\n",
       "        0.18477291,  0.37596652, -0.12123195,  0.37460417, -0.10941537,\n",
       "       -0.15382145, -0.24145173, -0.04533649,  0.0895906 ,  0.18612666,\n",
       "        0.04379981,  0.112929  , -0.30854538,  0.03296512, -0.6627337 ,\n",
       "        0.29506305, -0.38919705, -0.04696703,  0.3430997 , -0.16195764,\n",
       "       -0.2561122 , -0.3337363 ,  0.23679343, -0.01586354, -0.20077123,\n",
       "       -0.21673447, -0.34555817,  0.14487101, -0.57072604,  0.3544448 ,\n",
       "        0.25350264, -0.08715778,  0.11061372,  0.43735257, -0.07587079],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(train_corpus[100000].words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with new document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_sentence_vectors_from_document(doc, model):\n",
    "    vectors = []\n",
    "    sens = doc.split('.')\n",
    "    for sen in sens:\n",
    "        if len(sen) > 10:\n",
    "            sen = gensim.utils.simple_preprocess(sen)\n",
    "            sen = ' '.join(sen)\n",
    "            sen = ViTokenizer.tokenize(sen)\n",
    "            sen = sen.split(' ')\n",
    "            vec = model.infer_vector(sen)\n",
    "            \n",
    "            vectors.append(vec)\n",
    "    \n",
    "    return np.array(vectors), sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'Công sở đậm dư âm Tết trong ngày đầu làm việc. Trong lịch công tác của các bộ ngành 3 ngày đầu năm hầu như không có những cuộc họp. Chương trình làm việc chính của các lãnh đạo là chúc Tết. Một số nơi còn ghi lịch làm việc: lãnh đạo giải quyết công việc thường xuyên tại cơ quan. 9h sáng, hội trường Bộ Giáo dục và Đào tạo rộn tiếng cười đùa, chúc tụng, tiếng ly rượu cụng nhau chan chát. Sau đó các vụ, phòng bắt đầu những cuộc gặp gỡ riêng. Buổi \"làm việc\" đầu năm kết thúc sớm, với bữa tiệc tân niên tại gia. \"Ngày thường, cùng cơ quan đấy nhưng mấy khi có dịp đến nhà nhau. Năm qua, người thì xây nhà mới, người thì có con đầu lòng. Đầu xuân, mọi người trong phòng đến nhà nhau, vừa chúc Tết, thăm hỏi luôn\", anh Tuấn, cán bộ Tổng công ty Dệt may Việt Nam tâm sự.  Sau 2 màn tiệc ngọt tại cơ quan, 10h sáng, các thành viên trong phòng của Tuấn \"đóng cửa\" bắt đầu những cuộc viếng thăm truyền thống. \"Hôm nay ai có việc gấp quá thì phải làm nhưng ít người như thế lắm. Cả sếp và nhân viên công ty tôi đều đi chúc Tết. Chúc Tết các phòng xong, chúng tôi đang triệu nhau đến thăm nhà mấy người đồng nghiệp, bạn bè gần đây\", chị Nguyễn Thị Bích Thư, phòng Kỹ thuật, Công ty Thép Miền Nam, 56 Thủ Khoa Huân, quận 1 (TP HCM) hoan hỷ. Rộn ràng trong công sở, không khí xuân còn tràn ngập quanh các hàng quán cà phê. 9h sáng, nhưng các hàng quán trên đường Lý Tự Trọng, quận 1 (TP HCM) vẫn khá đông công chức. Họ kể chuyện chơi Tết, chúc tụng, trao lì xì cho nhau và vui vẻ cười đùa. Anh Hoàng, cán bộ một sở trên đường Lý Tự Trọng cho biết, ngày đầu năm, lãnh đạo sở gặp mặt lãnh đạo các phòng, ban, nhân viên, ăn kẹo, uống chút bia thân mật để động viên, lấy khí thế làm việc cho cả năm. Dư vị Tết có lẽ phải kéo dài thêm vài ngày nữa. Trao đổi với VnExpress, Chánh Văn phòng của một bộ cho rằng: Đầu năm chơi nhiều hơn làm đã thành lệ khó sửa. Lãnh đạo cơ quan biết nhưng cũng phải thông cảm. Anh em mời nhau đến nhà chơi, đi làm muộn một chút mình cũng phải thông cảm, quy định cứng nhắc quá thì mất vui. Tuy nhiên, công việc cơ quan vẫn phải đảm bảo, ông này nói. Cũng có một thực tế là đầu năm, người dân cũng mải vui Tết, chưa đến các cơ quan công quyền. Do vậy, không tạo áp lực công việc đối với công chức. Phòng công chứng số 1 (Hà Nội) ngày thường đông nghịt khách nhưng sáng nay vắng hoe. Anh Nguyễn Chí Thiện, công chứng viên cho biết, cả sáng chỉ có khoảng 30 hồ sơ công chứng, thấp kỷ lục trong năm. Vắng khách, sẵn mứt Tết tồn đọng, nhân viên quây quần ngồi uống nước, bàn chuyện du xuân. 11h trưa, nhiều công sở ở Hà Nội khá im ắng, các quán ăn thì đông nghẹt khách. Sáng đi được một tour rồi, trưa tụ họp ở quán ăn lấy sức. Chiều đi vài nhà nữa rồi karaoke, Ngọc Linh, nhân viên kinh doanh một hãng ôtô lớn hào hứng. Với nhiều công chức, ngày đầu năm đi làm còn. . vui hơn Tết!'\n",
    "\n",
    "sen_vectors, sens = get_list_sentence_vectors_from_document(doc, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 300)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sen_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "kmeans = kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Đầu xuân, mọi người trong phòng đến nhà nhau, vừa chúc Tết, thăm hỏi luôn\", anh Tuấn, cán bộ Tổng công ty Dệt may Việt Nam tâm sự\n",
      " 9h sáng, hội trường Bộ Giáo dục và Đào tạo rộn tiếng cười đùa, chúc tụng, tiếng ly rượu cụng nhau chan chát\n",
      " \n",
      " Anh Nguyễn Chí Thiện, công chứng viên cho biết, cả sáng chỉ có khoảng 30 hồ sơ công chứng, thấp kỷ lục trong năm\n",
      " Vắng khách, sẵn mứt Tết tồn đọng, nhân viên quây quần ngồi uống nước, bàn chuyện du xuân\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "avg = []\n",
    "for j in range(n_clusters):\n",
    "    idx = np.where(kmeans.labels_ == j)[0]\n",
    "    avg.append(np.mean(idx))\n",
    "closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, X)\n",
    "ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n",
    "summary = [sens[closest[idx]] for idx in ordering]\n",
    "\n",
    "for sen in summary:\n",
    "    print(sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
